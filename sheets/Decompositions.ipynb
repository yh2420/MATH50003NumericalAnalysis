{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Decompositions and least squares\n",
    "\n",
    "\n",
    "In this lecture, we look at several factorizations of a matrix. For a square or rectangular matrix $A ∈ ℝ^{m × n}$ with $m ≥ n$, we consider:\n",
    "1. The _QR decomposition_\n",
    "$$\n",
    "A = \\underbrace{Q}_{m × m} \\underbrace{R}_{m × n} = \\begin{bmatrix} 𝐪_1 | \\cdots | 𝐪_m \\end{bmatrix} \\begin{bmatrix} × & \\cdots & × \\\\ & \\ddots & \\vdots \\\\ && × \\\\ &&0 \\\\ &&\\vdots \\\\ && 0 \\end{bmatrix} \n",
    "$$\n",
    "where $Q$ is orthogonal ($Q^⊤Q = I$, $𝐪_j ∈ ℝ^m$) and $R$ is _right triangular_.\n",
    "\n",
    "2. The _reduced QR decomposition_\n",
    "$$\n",
    "A = \\underbrace{Q̂}_{m × n} \\underbrace{R̂}_{m × m} = \\begin{bmatrix} 𝐪_1 | \\cdots | 𝐪_n \\end{bmatrix} \\begin{bmatrix} × & \\cdots & × \\\\ & \\ddots & \\vdots \\\\ && ×  \\end{bmatrix} \n",
    "$$\n",
    "where $Q$ has orthogonal columns ($Q^⊤Q = I$, $𝐪_j ∈ ℝ^m$) \n",
    "\n",
    "For a square matrix we consider the _PLU decomposition_:\n",
    "$$\n",
    "A = P^⊤ LU\n",
    "$$\n",
    "where $P$ is a permutation matrix, $L$ is lower triangular and $U$ is upper triangular.\n",
    "\n",
    "Finally, for a square, _symmetric positive definite_ ($𝐱^⊤ A 𝐱 > 0$ for all $𝐱 ∈ ℝ^n$) \n",
    "matrix we consider the _Cholesky decomposition_:\n",
    "$$\n",
    "A = L L^⊤\n",
    "$$\n",
    "\n",
    "The importance of these decomposition for square matrices is that their component pieces are easy to invert on a computer:\n",
    "$$\n",
    "\\begin{align*}\n",
    "A = P^⊤ LU &\\Rightarrow\\qquad A^{-1}𝐛 = U^{-1} L^{-1} P 𝐛 \\\\\n",
    "A = QR &\\Rightarrow\\qquad A^{-1}𝐛 = R^{-1} Q^\\top 𝐛 \\\\\n",
    "A = L L^⊤ &\\Rightarrow\\qquad A^{-1}𝐛 = L^{-⊤} L^{-1} 𝐛\n",
    "\\end{align*}\n",
    "$$\n",
    "and we saw last lecture that triangular and orthogonal matrices are easy to invert when applied to a vector $𝐛$.\n",
    "For rectangular matrices we will see that they lead to efficient solutions to the _least squares problem_: find\n",
    "$𝐱$ that minimizes the 2-norm\n",
    "$$\n",
    "\\| A 𝐱 - 𝐛 \\|.\n",
    "$$\n",
    "\n",
    "In this lecture we discuss the followng:\n",
    "\n",
    "1. QR,  Reduced QR, and least squares: We discuss the QR decomposition and its usage in solving least squares problems.\n",
    "We discuss computation of the Reduced QR decomposition using Gram–Schmidt, and the Full QR decomposition using \n",
    "Householder reflections.\n",
    "2. PLU decomposition: we discuss how the LU decomposition can be computed using Gaussian elimination, and the computation of\n",
    "the PLU decomposition via Gaussian elimination with pivoting.\n",
    "3. Cholesky decomposition: we introduce symmetric positive definite matrices and show that their LU decomposition can be re-interpreted\n",
    "as a Cholesky decomposition."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-01-21T15:41:39.055318Z",
     "iopub.status.busy": "2022-01-21T15:41:38.654235Z",
     "iopub.status.idle": "2022-01-21T15:43:14.707990Z",
     "shell.execute_reply": "2022-01-21T15:43:14.707274Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "┌ Info: Precompiling Plots [91a5bcdd-55d7-5caf-9e0b-520d859cae80]\n",
      "└ @ Base loading.jl:1423\n"
     ]
    }
   ],
   "source": [
    "using LinearAlgebra, Plots"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. QR, Reduced QR, and least squares\n",
    "\n",
    "Here we consider rectangular matrices with more rows than columns.\n",
    "A QR decomposition decomposes a matrix into an orthogonal matrix $Q$ times a right triangular matrix $R$. \n",
    "Note the QR decomposition contains within it the reduced QR decomposition:\n",
    "$$\n",
    "A = QR = \\begin{bmatrix} Q̂ | 𝐪_{n+1} | ⋯ | 𝐪_m \\end{bmatrix} \\begin{bmatrix} R̂ \\\\  𝟎_{m-n × n} \\end{bmatrix} = Q̂ R̂.\n",
    "$$\n",
    "\n",
    "### Relationship with least squares\n",
    "\n",
    "We can use it to solve a least squares problem using the norm-preserving property (see PS3) of orthogonal matrices:\n",
    "$$\n",
    "\\| A 𝐱 - 𝐛 \\| = \\| Q R 𝐱 - 𝐛 \\| = \\| R 𝐱 - Q^⊤ 𝐛 \\| = \\left \\| \n",
    "\\begin{bmatrix} R̂ \\\\ 𝟎_{m-n × n} \\end{bmatrix} 𝐱 - \\begin{bmatrix} Q̂^⊤ \\\\ 𝐪_{n+1}^⊤ \\\\ \\vdots \\\\ 𝐪_m^⊤ \\end{bmatrix}     𝐛 \\right \\|\n",
    "$$\n",
    "Now note that the rows $k > n$ are independent of $𝐱$ and are a fixed contribution. Thus to minimise this norm it suffices to\n",
    "drop them and minimise:\n",
    "$$\n",
    "\\| R̂ 𝐱 - Q̂^⊤ 𝐛 \\|\n",
    "$$\n",
    "This norm is minimisable if it is attained. Provided the column rank of $A$ is full, $R̂$ will be invertible (Exercise: why is this?).\n",
    "Thus we have the solution\n",
    "$$\n",
    "𝐱 = R̂^{-1} Q̂^⊤ 𝐛\n",
    "$$\n",
    "\n",
    "Let's look at an example. Suppose we want to find noisy data by a quadratic\n",
    "$$\n",
    "p(x) = a + bx + cx^2\n",
    "$$\n",
    "That is, we want to choose $a,b,c$ at data samples $x_1, \\ldots, x_m$ so that the following is true:\n",
    "$$\n",
    "a + b x_k + c x_k^2 ≈ f_k\n",
    "$$\n",
    "where $f_k$ are given by data. We can reinterpret this as a least squares problem: minimise the norm\n",
    "$$\n",
    "\\left\\| \\begin{bmatrix} 1 & x_1 & x_1^2 \\\\ \\vdots & \\vdots & \\vdots \\\\ 1 & x_m & x_m^2 \\end{bmatrix}\n",
    "\\begin{bmatrix} a \\\\ b \\\\ c \\end{bmatrix} - \\begin{bmatrix} f_1 \\\\ \\vdots \\\\ f_m \\end{bmatrix} \\right \\|\n",
    "$$\n",
    "We can solve this using the QR decomposition:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-01-21T15:43:15.722860Z",
     "iopub.status.busy": "2022-01-21T15:43:14.710348Z",
     "iopub.status.idle": "2022-01-21T15:43:17.335553Z",
     "shell.execute_reply": "2022-01-21T15:43:17.335108Z"
    }
   },
   "outputs": [
    {
     "ename": "LoadError",
     "evalue": "UndefVarError: R not defined",
     "output_type": "error",
     "traceback": [
      "UndefVarError: R not defined",
      "",
      "Stacktrace:",
      " [1] top-level scope",
      "   @ In[2]:8",
      " [2] eval",
      "   @ ./boot.jl:373 [inlined]",
      " [3] include_string(mapexpr::typeof(REPL.softscope), mod::Module, code::String, filename::String)",
      "   @ Base ./loading.jl:1196"
     ]
    }
   ],
   "source": [
    "x = range(0,1; length=100) # 1000 points\n",
    "f = 2 .+ x .+ 2x.^2 .+ 0.1 .* randn.() # Noisy quadratic\n",
    "\n",
    "A = [ones(length(x)) x x.^2]\n",
    "Q,R̂ = qr(A)\n",
    "Q̂ = Q[:,1:3] # Q represents full orthogonal matrix so we take first 3 columns\n",
    "\n",
    "a,b,c = R \\ Q̂'f"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can visualise the fit:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-01-21T15:43:17.337726Z",
     "iopub.status.busy": "2022-01-21T15:43:17.337114Z",
     "iopub.status.idle": "2022-01-21T15:43:20.181785Z",
     "shell.execute_reply": "2022-01-21T15:43:20.181336Z"
    }
   },
   "outputs": [
    {
     "ename": "LoadError",
     "evalue": "UndefVarError: b not defined",
     "output_type": "error",
     "traceback": [
      "UndefVarError: b not defined",
      "",
      "Stacktrace:",
      " [1] (::var\"#1#2\")(x::Float64)",
      "   @ Main ./In[3]:1",
      " [2] _broadcast_getindex_evalf",
      "   @ ./broadcast.jl:670 [inlined]",
      " [3] _broadcast_getindex",
      "   @ ./broadcast.jl:643 [inlined]",
      " [4] getindex",
      "   @ ./broadcast.jl:597 [inlined]",
      " [5] copy",
      "   @ ./broadcast.jl:899 [inlined]",
      " [6] materialize(bc::Base.Broadcast.Broadcasted{Base.Broadcast.DefaultArrayStyle{1}, Nothing, var\"#1#2\", Tuple{StepRangeLen{Float64, Base.TwicePrecision{Float64}, Base.TwicePrecision{Float64}, Int64}}})",
      "   @ Base.Broadcast ./broadcast.jl:860",
      " [7] top-level scope",
      "   @ In[3]:4",
      " [8] eval",
      "   @ ./boot.jl:373 [inlined]",
      " [9] include_string(mapexpr::typeof(REPL.softscope), mod::Module, code::String, filename::String)",
      "   @ Base ./loading.jl:1196"
     ]
    }
   ],
   "source": [
    "p = x -> a + b*x + c*x^2\n",
    "\n",
    "scatter(x, f; label=\"samples\", legend=:bottomright)\n",
    "plot!(x, p.(x); label=\"quadratic\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note that `\\` with a rectangular system does least squares by default:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-01-21T15:43:20.183750Z",
     "iopub.status.busy": "2022-01-21T15:43:20.183168Z",
     "iopub.status.idle": "2022-01-21T15:43:22.233194Z",
     "shell.execute_reply": "2022-01-21T15:43:22.232704Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3-element Vector{Float64}:\n",
       " 2.0061494545254637\n",
       " 1.0329624031651745\n",
       " 1.9524446508610185"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "A \\ f"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Gram–Schmidt and reduced QR\n",
    "\n",
    "We will now reinterpret \n",
    "\n",
    "### Householder reflections and QR\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "## 2. PLU Decomposition\n",
    "\n",
    "\n",
    "## 3."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Julia 1.7.0",
   "language": "julia",
   "name": "julia-1.7"
  },
  "language_info": {
   "file_extension": ".jl",
   "mimetype": "application/julia",
   "name": "julia",
   "version": "1.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
